{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions.uniform import Uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple hack to support import module from parent directory\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from instruct_llama.utils import RunningMeanStd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.3863, -0.9163, -0.6931, -0.5596, -0.4700, -0.4055])\n",
      "tensor([-1.3863, -0.9163, -0.6931, -0.5596, -0.4700, -0.4055])\n",
      "tensor([1.3863, 0.9163, 0.6931, 0.5596, 0.4700, 0.4055])\n",
      "tensor([1.3863, 0.9163, 0.6931, 0.5596, 0.4700, 0.4055])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1306948/2649817897.py:1: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  a = torch.range(0.1, 0.6, 0.1)\n",
      "/tmp/ipykernel_1306948/2649817897.py:2: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  b = torch.range(0.4, 0.9, 0.1)\n"
     ]
    }
   ],
   "source": [
    "a = torch.range(0.1, 0.6, 0.1)\n",
    "b = torch.range(0.4, 0.9, 0.1)\n",
    "\n",
    "print(torch.log(a/b))\n",
    "print(torch.log(a) - torch.log(b))\n",
    "\n",
    "print(torch.log(b/a))\n",
    "print(torch.log(b) - torch.log(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "# Example tensors\n",
    "tensor1 = torch.tensor([1, 2, 3])\n",
    "tensor2 = torch.tensor([4, 5, 6, 7, 8])\n",
    "\n",
    "# Calculate the difference in lengths\n",
    "length_diff = len(tensor2) - len(tensor1)\n",
    "\n",
    "# Pad tensor1 to match the length of tensor2\n",
    "if length_diff > 0:\n",
    "    padded_tensor1 = F.pad(tensor1, (0, length_diff), value=0)\n",
    "else:\n",
    "    # Handle the case where tensor1 is longer or equal in length to tensor2\n",
    "    padded_tensor1 = tensor1\n",
    "\n",
    "print(padded_tensor1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_mean(tensor: torch.Tensor, mask: torch.Tensor, dim: int = 1) -> torch.Tensor:\n",
    "    tensor = tensor * mask\n",
    "    tensor = tensor.sum(dim=dim)\n",
    "    mask_sum = mask.sum(dim=dim)\n",
    "\n",
    "    # avoid division by zero\n",
    "    mask_sum = torch.where(mask_sum <= 0, 1e-8, mask_sum)\n",
    "\n",
    "    mean = tensor / mask_sum\n",
    "    return mean\n",
    "\n",
    "\n",
    "def masked_sum(tensor: torch.Tensor, mask: torch.Tensor, dim: int = 1) -> torch.Tensor:\n",
    "    tensor = tensor * mask\n",
    "    sum = tensor.sum(dim=dim)\n",
    "    return sum\n",
    "\n",
    "\n",
    "def masked_whiten(\n",
    "    tensor: torch.Tensor, mask: torch.Tensor, dim: int = 1, eps: float = 1e-8, shift_mean: bool = True\n",
    ") -> torch.Tensor:\n",
    "    tensor = tensor * mask\n",
    "    mean = masked_mean(tensor, mask, dim=dim)\n",
    "\n",
    "    if len(tensor.shape) > len(mean.shape):\n",
    "        mean = mean.unsqueeze(1)\n",
    "\n",
    "    mean_centered = tensor - mean\n",
    "    var = masked_mean(mean_centered**2, mask, dim=dim)\n",
    "    if len(tensor.shape) > len(var.shape):\n",
    "        var = var.unsqueeze(1)\n",
    "\n",
    "    whitened = mean_centered * var.clamp(min=eps).rsqrt()\n",
    "\n",
    "    if not shift_mean:\n",
    "        whitened += mean\n",
    "\n",
    "    return whitened\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "rewards = Uniform(1, 5).sample((32, 100))\n",
    "mask = torch.where(rewards > 4, 0, 1)\n",
    "\n",
    "mean = masked_mean(rewards, mask)\n",
    "print(mean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.6464, -1.2026,  0.2889,  ...,  0.9180, -0.2109, -1.2180],\n",
      "        [-1.2525,  1.0659,  0.3704,  ..., -1.5527,  1.3320, -2.9028],\n",
      "        [-3.1446, -1.2506,  0.5387,  ..., -3.1446, -3.1446, -3.1446],\n",
      "        ...,\n",
      "        [-2.8881,  0.5655, -0.8311,  ...,  1.2368, -2.8881,  1.0424],\n",
      "        [ 0.0600, -2.9786,  0.3721,  ..., -1.6684, -1.1566,  0.3989],\n",
      "        [-0.5544,  0.6849, -3.1889,  ..., -3.1889,  0.5617, -1.3843]])\n"
     ]
    }
   ],
   "source": [
    "print(masked_whiten(rewards, mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern found at index: 3\n"
     ]
    }
   ],
   "source": [
    "def find_pattern_index(lst, pattern):\n",
    "    pattern_length = len(pattern)\n",
    "    lst_length = len(lst)\n",
    "\n",
    "    for i in range(lst_length - pattern_length + 1):\n",
    "        if lst[i:i + pattern_length] == pattern:\n",
    "            return i\n",
    "\n",
    "    return -1  # Return -1 if pattern is not found\n",
    "\n",
    "# Example list and pattern\n",
    "my_list = [123, 456, 331, 518, 25580, 29962, 789, 518, 25580, 29962]\n",
    "my_pattern = [518, 25580, 29962]\n",
    "\n",
    "# Find the index of the first occurrence of the pattern\n",
    "index = find_pattern_index(my_list, my_pattern)\n",
    "\n",
    "if index != -1:\n",
    "    print(\"Pattern found at index:\", index)\n",
    "else:\n",
    "    print(\"Pattern not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = RunningMeanStd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.3305, 4.2210, 3.0239, 1.5279, 2.9952, 4.6518, 4.1763, 3.7775, 3.2323,\n",
      "        3.7950, 1.6351, 2.1434, 2.0246, 2.2833, 2.7809, 4.1443, 1.5020, 4.1390,\n",
      "        3.3725, 4.0163, 3.6551, 3.6362, 3.1837, 1.4609, 1.1217, 4.0624, 1.6084,\n",
      "        3.0058, 1.8046, 4.4765, 1.0956, 2.8427])\n",
      "tensor([2.3305, 4.2210, 3.0239, 1.5279, 2.9952, 4.6518, 4.1763, 3.7775, 3.2323,\n",
      "        3.7950, 1.6351, 2.1434, 2.0246, 2.2833, 2.7809, 4.1443, 1.5020, 4.1390,\n",
      "        3.3725, 4.0163, 3.6551, 3.6362, 3.1837, 1.4609, 1.1217, 4.0624, 1.6084,\n",
      "        3.0058, 1.8046, 4.4765, 1.0956, 2.8427])\n",
      "--------------------------------------------------------------------------------\n",
      "tensor([2.5978, 3.3823, 3.3522, 1.5136, 3.6318, 4.8554, 1.6120, 1.1887, 2.0239,\n",
      "        2.0285, 3.2207, 1.5096, 3.1732, 1.4625, 3.8015, 3.5378, 3.9452, 2.4192,\n",
      "        3.6837, 1.1092, 3.4495, 2.7614, 4.3623, 1.1907, 3.7079, 4.1499, 2.5371,\n",
      "        3.7045, 4.5393, 3.6307, 3.6911, 3.8957])\n",
      "tensor([-0.1060,  0.1451,  0.1355, -0.4531,  0.2250,  0.6167, -0.4216, -0.5571,\n",
      "        -0.2897, -0.2882,  0.0934, -0.4544,  0.0782, -0.4694,  0.2793,  0.1949,\n",
      "         0.3253, -0.1632,  0.2416, -0.5825,  0.1666, -0.0536,  0.4589, -0.5565,\n",
      "         0.2494,  0.3909, -0.1254,  0.2483,  0.5155,  0.2246,  0.2440,  0.3095])\n",
      "--------------------------------------------------------------------------------\n",
      "tensor([4.6020, 1.4479, 1.3308, 3.8440, 2.9041, 3.7520, 4.2110, 4.4273, 1.5839,\n",
      "        2.3696, 1.3817, 4.2567, 1.3972, 1.9859, 2.0873, 3.0330, 2.4700, 4.6822,\n",
      "        1.8988, 2.7863, 3.5655, 4.5429, 4.1977, 1.7400, 4.0174, 4.9322, 2.1558,\n",
      "        4.5436, 2.5994, 2.2141, 3.9693, 1.6069])\n",
      "tensor([ 0.7024, -0.6463, -0.6964,  0.3783, -0.0236,  0.3390,  0.5353,  0.6278,\n",
      "        -0.5882, -0.2522, -0.6746,  0.5548, -0.6680, -0.4163, -0.3729,  0.0315,\n",
      "        -0.2092,  0.7368, -0.4535, -0.0740,  0.2592,  0.6772,  0.5296, -0.5214,\n",
      "         0.4525,  0.8437, -0.3436,  0.6775, -0.1539, -0.3187,  0.4319, -0.5783])\n",
      "--------------------------------------------------------------------------------\n",
      "tensor([3.0595, 1.2686, 1.1180, 4.6084, 4.0321, 2.0147, 4.9847, 3.1424, 4.2657,\n",
      "        4.5309, 3.7433, 2.6335, 1.3232, 3.8442, 2.7565, 2.0048, 4.4616, 2.3370,\n",
      "        4.5979, 3.7345, 1.1119, 4.3768, 1.8065, 2.7287, 3.9594, 4.1981, 2.5266,\n",
      "        4.1276, 4.4090, 3.4007, 4.2977, 2.4375])\n",
      "tensor([ 0.0399, -0.8411, -0.9152,  0.8018,  0.5183, -0.4741,  0.9869,  0.0806,\n",
      "         0.6332,  0.7637,  0.3762, -0.1697, -0.8143,  0.4258, -0.1092, -0.4789,\n",
      "         0.7296, -0.3155,  0.7966,  0.3719, -0.9182,  0.6878, -0.5765, -0.1228,\n",
      "         0.4825,  0.5999, -0.2223,  0.5653,  0.7037,  0.2077,  0.6489, -0.2661])\n",
      "--------------------------------------------------------------------------------\n",
      "tensor([4.1225, 1.7605, 3.0512, 2.8148, 1.1855, 3.3178, 4.3936, 1.8046, 1.7107,\n",
      "        2.8693, 4.6866, 2.2584, 1.5193, 3.1214, 2.8995, 3.6951, 4.7929, 1.7156,\n",
      "        1.5165, 2.5402, 2.9055, 2.4532, 1.0547, 1.7884, 1.9898, 1.2777, 2.3038,\n",
      "        3.1771, 1.4013, 2.1762, 3.2210, 3.1540])\n",
      "tensor([ 0.5789, -0.6902,  0.0033, -0.1237, -0.9991,  0.1465,  0.7245, -0.6665,\n",
      "        -0.7169, -0.0944,  0.8819, -0.4227, -0.8198,  0.0410, -0.0782,  0.3492,\n",
      "         0.9390, -0.7143, -0.8213, -0.2713, -0.0750, -0.3180, -1.0694, -0.6752,\n",
      "        -0.5670, -0.9496, -0.3983,  0.0709, -0.8832, -0.4668,  0.0945,  0.0585])\n",
      "--------------------------------------------------------------------------------\n",
      "tensor([2.7865, 1.4576, 2.4013, 1.4018, 1.0548, 2.7889, 3.1874, 3.5661, 2.9475,\n",
      "        3.5888, 2.2410, 4.0880, 3.6010, 2.3361, 4.3521, 2.0990, 4.3500, 2.7871,\n",
      "        3.0655, 4.3486, 3.0467, 3.1638, 1.9735, 3.3950, 4.6324, 1.7311, 1.3536,\n",
      "        3.5112, 1.8358, 4.8418, 4.4560, 2.1068])\n",
      "tensor([-0.0957, -0.8599, -0.3172, -0.8920, -1.0915, -0.0943,  0.1349,  0.3527,\n",
      "        -0.0031,  0.3658, -0.4093,  0.6528,  0.3728, -0.3547,  0.8047, -0.4911,\n",
      "         0.8035, -0.0953,  0.0648,  0.8027,  0.0540,  0.1213, -0.5632,  0.2543,\n",
      "         0.9659, -0.7026, -0.9197,  0.3211, -0.6424,  1.0864,  0.8645, -0.4865])\n",
      "--------------------------------------------------------------------------------\n",
      "tensor([2.5201, 1.0293, 2.9460, 2.6526, 4.5537, 1.3799, 3.2753, 3.9324, 1.0944,\n",
      "        1.3243, 4.0084, 4.5156, 4.1787, 4.0745, 1.4324, 2.2982, 4.3177, 1.3058,\n",
      "        3.8311, 2.1620, 4.4083, 2.1338, 2.2555, 1.4682, 1.8082, 1.7301, 2.2397,\n",
      "        1.7786, 4.5737, 4.7304, 1.4414, 1.8101])\n",
      "tensor([-0.2630, -1.1691, -0.0042, -0.1825,  0.9730, -0.9560,  0.1960,  0.5953,\n",
      "        -1.1296, -0.9898,  0.6416,  0.9498,  0.7451,  0.6818, -0.9241, -0.3979,\n",
      "         0.8296, -1.0011,  0.5338, -0.4807,  0.8846, -0.4978, -0.4238, -0.9024,\n",
      "        -0.6957, -0.7432, -0.4335, -0.7137,  0.9852,  1.0804, -0.9187, -0.6946])\n",
      "--------------------------------------------------------------------------------\n",
      "tensor([2.3974, 4.7583, 1.0776, 3.9114, 3.5554, 4.8162, 4.9173, 2.5217, 3.3504,\n",
      "        2.4784, 1.4381, 2.9939, 3.8014, 1.8778, 3.7161, 3.3556, 1.7355, 2.0315,\n",
      "        2.7407, 3.3105, 3.7156, 3.1757, 3.3304, 3.3279, 4.1722, 4.5494, 1.1487,\n",
      "        4.9678, 4.4586, 1.7442, 4.2743, 3.1913])\n",
      "tensor([-0.3272,  1.1501, -1.1531,  0.6201,  0.3974,  1.1863,  1.2495, -0.2494,\n",
      "         0.2691, -0.2766, -0.9275,  0.0460,  0.5513, -0.6523,  0.4979,  0.2724,\n",
      "        -0.7414, -0.5562, -0.1124,  0.2441,  0.4976,  0.1598,  0.2566,  0.2550,\n",
      "         0.7833,  1.0194, -1.1086,  1.2812,  0.9625, -0.7360,  0.8472,  0.1695])\n",
      "--------------------------------------------------------------------------------\n",
      "tensor([1.3399, 3.1969, 3.8502, 1.9155, 1.0249, 1.5959, 1.7481, 3.3820, 2.0006,\n",
      "        3.1861, 3.0824, 1.5265, 4.6369, 2.9655, 3.9711, 3.8934, 1.1987, 3.4687,\n",
      "        3.9395, 2.0136, 1.1206, 3.7952, 1.0828, 3.3906, 3.1375, 4.8538, 2.6339,\n",
      "        1.8682, 1.8516, 4.6483, 4.0669, 4.4350])\n",
      "tensor([-1.0430,  0.1547,  0.5761, -0.6718, -1.2462, -0.8779, -0.7797,  0.2741,\n",
      "        -0.6169,  0.1477,  0.0809, -0.9226,  1.0834,  0.0055,  0.6540,  0.6039,\n",
      "        -1.1341,  0.3300,  0.6336, -0.6085, -1.1844,  0.5406, -1.2088,  0.2796,\n",
      "         0.1164,  1.2234, -0.2084, -0.7023, -0.7129,  1.0908,  0.7158,  0.9532])\n",
      "--------------------------------------------------------------------------------\n",
      "tensor([1.7815, 4.1000, 3.5275, 4.7902, 1.3788, 1.1368, 2.0225, 3.2877, 1.4113,\n",
      "        2.5223, 3.0314, 2.6042, 3.7416, 4.9365, 1.2625, 3.1021, 2.9281, 1.6806,\n",
      "        2.7521, 4.3584, 4.0813, 4.5118, 2.1846, 2.0385, 3.9220, 1.6968, 4.5209,\n",
      "        1.1041, 4.4516, 4.4059, 1.5970, 1.8922])\n",
      "tensor([-0.7668,  0.7627,  0.3850,  1.2180, -1.0324, -1.1921, -0.6078,  0.2268,\n",
      "        -1.0110, -0.2781,  0.0577, -0.2241,  0.5263,  1.3145, -1.1091,  0.1044,\n",
      "        -0.0104, -0.8333, -0.1265,  0.9332,  0.7504,  1.0343, -0.5008, -0.5972,\n",
      "         0.6453, -0.8227,  1.0404, -1.2137,  0.9947,  0.9645, -0.8885, -0.6938])\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    rewards = Uniform(1, 5).sample((32,))\n",
    "    rewards_normed = normalizer.normalize(rewards)\n",
    "\n",
    "    print(rewards)\n",
    "    print(rewards_normed)\n",
    "    print('-'*80)\n",
    "    normalizer.update(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 32\n",
    "response_length=32\n",
    "gamma = 1.0\n",
    "gae_lambda = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.9976, -1.9505,  0.3911,  0.5321, -0.8263, -0.8723, -0.4773,  0.9948,\n",
      "         -0.8882,  0.0343, -0.8034,  1.3666,  0.5070,  0.1407,  0.2962,  1.2644,\n",
      "          1.2184,  0.3032,  0.2709,  0.9851, -1.0642,  1.8545,  0.5080,  1.0328,\n",
      "         -0.0914, -1.0718, -0.6253, -1.9257, -0.7694,  1.5111, -1.4778, -0.0999],\n",
      "        [ 0.0704,  1.2708,  1.3660, -1.4567, -1.7659,  0.6596,  0.1654,  1.8031,\n",
      "          1.3858, -0.3607,  0.9536,  0.3245,  0.0842, -1.5950, -0.8751, -1.8475,\n",
      "         -0.7938, -0.7384,  1.8661,  0.4114,  0.9599, -1.1225, -1.6356,  0.5733,\n",
      "          1.7450, -1.6083,  0.8860, -1.0427,  1.3411,  1.1768,  0.7282, -1.8170]])\n",
      "tensor([[-0.5760, -0.3617, -0.7945, -0.8109, -0.8843, -0.1325,  0.7195, -0.8992,\n",
      "          0.2091, -0.4879,  0.8301,  0.0372,  0.1386, -0.9673,  0.1793, -0.9158,\n",
      "         -0.8970, -0.1553,  0.0554,  0.7365,  0.5238,  0.3480, -0.7212,  0.2770,\n",
      "          0.8277,  0.6249,  0.2147,  0.0265,  0.0330,  0.3872,  0.2065, -0.0400],\n",
      "        [-0.5509, -0.1300,  0.4881, -0.2053,  0.7090,  0.1727,  0.8976,  0.7074,\n",
      "         -0.2067,  0.9024, -0.6522,  0.2327,  0.9587, -0.6254,  0.4304,  0.9184,\n",
      "         -0.9809,  0.7697, -0.8853,  0.2684,  0.7255, -0.6354, -0.0735, -0.9940,\n",
      "          0.7587,  0.8939, -0.3428,  0.9991, -0.4718,  0.8066, -0.0119,  0.0988]])\n"
     ]
    }
   ],
   "source": [
    "values = Uniform(-2, 2).sample((2, max_len))\n",
    "rewards = Uniform(-1, 1).sample((2, max_len))\n",
    "print(values)\n",
    "print(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_returns_advantages_openai(rewards, values):\n",
    "\n",
    "    lastgaelam = 0\n",
    "    advantages_reversed = []\n",
    "    gen_length = response_length\n",
    "    for t in reversed(range(gen_length)):\n",
    "        nextvalues = values[:, t + 1] if t < gen_length - 1 else 0.0\n",
    "        delta = rewards[:, t] + gamma * nextvalues - values[:, t]\n",
    "        lastgaelam = delta + gamma * gae_lambda * lastgaelam\n",
    "        advantages_reversed.append(lastgaelam)\n",
    "    advantages = torch.stack(advantages_reversed[::-1], dim=1)\n",
    "    returns = advantages + values\n",
    "\n",
    "    return returns, advantages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3.0821, -2.5354, -2.3086, -1.6218, -0.8101,  0.1241,  0.2952, -0.4990,\n",
      "          0.4680,  0.2707,  0.8408, -0.0607, -0.1297, -0.2899,  0.6974,  0.4789,\n",
      "          1.4039,  2.4060,  2.6819,  2.7130,  2.1365,  1.6000,  1.2911,  2.0639,\n",
      "          1.8857,  1.1701,  0.6068,  0.5141,  0.5537,  0.4686,  0.1635, -0.0400],\n",
      "        [ 2.5998,  3.2496,  3.4855,  3.2318,  3.7110,  3.1253,  3.0992,  2.2227,\n",
      "          1.5220,  1.8387,  0.9354,  1.6541,  1.4918,  0.6452,  1.3835,  1.1005,\n",
      "          0.2335,  1.3172,  0.4781,  1.4135,  1.1548,  0.5110,  1.2928,  1.4081,\n",
      "          2.4366,  1.8509,  0.9607,  1.4270,  0.3798,  0.8345, -0.0089,  0.0988]])\n",
      "tensor([[-2.0845, -0.5849, -2.6997, -2.1539,  0.0163,  0.9964,  0.7725, -1.4938,\n",
      "          1.3562,  0.2364,  1.6442, -1.4273, -0.6367, -0.4306,  0.4012, -0.7855,\n",
      "          0.1855,  2.1029,  2.4110,  1.7279,  3.2007, -0.2545,  0.7832,  1.0310,\n",
      "          1.9772,  2.2420,  1.2322,  2.4398,  1.3231, -1.0425,  1.6413,  0.0599],\n",
      "        [ 2.5294,  1.9788,  2.1195,  4.6885,  5.4769,  2.4656,  2.9338,  0.4196,\n",
      "          0.1362,  2.1994, -0.0182,  1.3297,  1.4076,  2.2402,  2.2586,  2.9480,\n",
      "          1.0273,  2.0555, -1.3880,  1.0021,  0.1950,  1.6335,  2.9284,  0.8348,\n",
      "          0.6917,  3.4593,  0.0747,  2.4698, -0.9613, -0.3423, -0.7371,  1.9158]])\n"
     ]
    }
   ],
   "source": [
    "returns, advantages = compute_returns_advantages_openai(rewards, values)\n",
    "print(returns)\n",
    "print(advantages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_returns_and_advantages(rewards, values, values_tp1, done_tp1):\n",
    "    # TODO investigate if should we use a special normalization process, as our rewards and state values contains lots of 0s,\n",
    "\n",
    "    num_rows, num_cols = values.shape  # Get the dimensions of the input data\n",
    "    discount_tp1 = (~done_tp1).float() * gamma\n",
    "\n",
    "    lambda_ = torch.ones_like(discount_tp1) * gae_lambda  # If scalar, make into vector.\n",
    "    delta_t = rewards + discount_tp1 * values_tp1 - values\n",
    "    advantages = torch.zeros_like(delta_t, dtype=torch.float)\n",
    "\n",
    "    returns = torch.zeros_like(advantages, dtype=torch.float)  # Initialize the returns tensor\n",
    "\n",
    "    for row in range(num_rows):\n",
    "        gae_t = 0\n",
    "        for col in reversed(range(num_cols)):\n",
    "            gae_t = delta_t[row, col] + discount_tp1[row, col] * lambda_[row, col] * gae_t\n",
    "            advantages[row, col] = gae_t\n",
    "        returns[row] = advantages[row] + values[row]\n",
    "\n",
    "    return returns, advantages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3.0729, -2.5257, -2.2984, -1.6110, -0.7987,  0.1360,  0.3078, -0.4858,\n",
      "          0.4819,  0.2854,  0.8562, -0.0445, -0.1126, -0.2719,  0.7164,  0.4988,\n",
      "          1.4249,  2.4281,  2.7052,  2.7374,  2.1623,  1.6271,  1.3197,  2.0939,\n",
      "          1.9174,  1.2034,  0.6419,  0.5510,  0.5925,  0.5095,  0.2065, -0.0400],\n",
      "        [ 2.5991,  3.2489,  3.4848,  3.2311,  3.7102,  3.1244,  3.0984,  2.2217,\n",
      "          1.5211,  1.8377,  0.9344,  1.6530,  1.4906,  0.6439,  1.3822,  1.0992,\n",
      "          0.2321,  1.3156,  0.4765,  1.4118,  1.1530,  0.5091,  1.2908,  1.4060,\n",
      "          2.4344,  1.8486,  0.9583,  1.4245,  0.3771,  0.8316, -0.0119,  0.0988]])\n",
      "tensor([[-2.0753, -0.5751, -2.6895, -2.1431,  0.0276,  1.0084,  0.7850, -1.4806,\n",
      "          1.3701,  0.2511,  1.6596, -1.4111, -0.6197, -0.4126,  0.4201, -0.7656,\n",
      "          0.2065,  2.1250,  2.4343,  1.7523,  3.2265, -0.2274,  0.8117,  1.0611,\n",
      "          2.0088,  2.2753,  1.2672,  2.4767,  1.3619, -1.0017,  1.6843,  0.0599],\n",
      "        [ 2.5287,  1.9781,  2.1188,  4.6877,  5.4761,  2.4648,  2.9329,  0.4187,\n",
      "          0.1352,  2.1984, -0.0192,  1.3285,  1.4064,  2.2389,  2.2573,  2.9466,\n",
      "          1.0259,  2.0540, -1.3896,  1.0004,  0.1932,  1.6316,  2.9264,  0.8327,\n",
      "          0.6895,  3.4569,  0.0723,  2.4672, -0.9640, -0.3451, -0.7401,  1.9158]])\n"
     ]
    }
   ],
   "source": [
    "dones = torch.zeros_like(values, dtype=torch.bool)\n",
    "dones[:, -1] = True\n",
    "values_tp1 = torch.zeros_like(values)\n",
    "done_tp1 = torch.ones_like(values, dtype=torch.bool)\n",
    "values_tp1[:, :-1] = values[:, 1:]\n",
    "done_tp1[:, :-1] = dones[:, 1:]\n",
    "\n",
    "returns, advantages = compute_returns_and_advantages(rewards, values, values_tp1, done_tp1)\n",
    "print(returns)\n",
    "print(advantages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])\n",
      "tensor([False, False, False, False, False, False, False, False, False, False])\n"
     ]
    }
   ],
   "source": [
    "tokens = torch.tensor(range(1, 11))\n",
    "print(tokens)\n",
    "\n",
    "dones = torch.zeros_like(tokens).to(dtype=torch.bool)\n",
    "print(dones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 1, 1, 1, 1, 0, 0, 0])\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 0, 0, 0])\n",
      "tensor([False, False, False, False, False, False,  True,  True,  True,  True])\n"
     ]
    }
   ],
   "source": [
    "start = 4\n",
    "end = 7\n",
    "\n",
    "masked_values = torch.zeros_like(tokens)\n",
    "masked_returns = torch.ones_like(tokens)\n",
    "masked_dones = torch.zeros_like(dones).to(dtype=torch.bool)\n",
    "\n",
    "masked_values[start-1:end] = 1\n",
    "masked_returns[end:] = 0.0\n",
    "masked_dones[end-1:] = True\n",
    "\n",
    "print(masked_values)\n",
    "print(masked_returns)\n",
    "print(masked_dones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1,  2,  3,  4,  5,  6,  7, -1, -1, -1])\n"
     ]
    }
   ],
   "source": [
    "tokens[end:] = -1\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.4321, -0.9113, -0.3906],\n",
      "        [ 0.1302,  0.6509,  1.1717]])\n"
     ]
    }
   ],
   "source": [
    "def whiten_with_mask(values, mask, shift_mean=True):\n",
    "    masked_values = torch.masked_select(values, mask)\n",
    "    mean = torch.mean(masked_values)\n",
    "    var = torch.var(masked_values, unbiased=False)  # PyTorch uses biased variance estimation by default\n",
    "    \n",
    "    whitened = (values - mean) * torch.rsqrt(var + 1e-8)\n",
    "    if not shift_mean:\n",
    "        whitened += mean\n",
    "    return whitened\n",
    "\n",
    "# Example usage:\n",
    "values = torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "mask = torch.tensor([[True, False, True], [False, True, True]])\n",
    "whitened = whiten_with_mask(values, mask, shift_mean=True)\n",
    "print(whitened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.4639, -0.8783, -0.2928],\n",
      "        [ 0.2928,  0.8783,  1.4639]])\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "values = torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "mask = torch.tensor([[True, True, True], [True, True, True]])\n",
    "whitened = whiten_with_mask(values, mask, shift_mean=True)\n",
    "print(whitened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "mask = torch.tensor([[False, False, False, False,  True,  True,  True,  True,  False,  False],\n",
    "                     [False, False, False, False,  False,  True,  True,  True,  False,  False],\n",
    "        [False, False, False, False, True, True, True, True,  True,  True]], dtype=bool)\n",
    "\n",
    "# Convert mask to float tensor\n",
    "mask_float = mask.float()\n",
    "\n",
    "# Calculate the sum of mask values along the appropriate axis\n",
    "sum_mask_values = mask_float.sum(dim=1)  # Assuming dim=1 is the appropriate axis\n",
    "\n",
    "# Create a boolean tensor indicating which episodes meet the condition\n",
    "condition_met = sum_mask_values >= 4\n",
    "\n",
    "# Count the number of True values in the boolean tensor\n",
    "print(condition_met.sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern found at index: 3\n"
     ]
    }
   ],
   "source": [
    "def find_pattern_index(tensor, pattern):\n",
    "    pattern_length = pattern.size(0)\n",
    "    tensor_length = tensor.size(0)\n",
    "\n",
    "    for i in range(tensor_length - pattern_length + 1):\n",
    "        if torch.equal(tensor[i:i+pattern_length], pattern):\n",
    "            return i\n",
    "\n",
    "    return -1  # Return -1 if pattern is not found\n",
    "\n",
    "# Example tensor and pattern\n",
    "my_tensor = torch.tensor([123, 456, 331, 518, 25580, 29962, 789, 518, 25580, 29962])\n",
    "my_pattern = torch.tensor([518, 25580, 29962])\n",
    "\n",
    "# Find the index of the first occurrence of the pattern\n",
    "index = find_pattern_index(my_tensor, my_pattern)\n",
    "\n",
    "if index != -1:\n",
    "    print(\"Pattern found at index:\", index)\n",
    "else:\n",
    "    print(\"Pattern not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern found at index: 10\n"
     ]
    }
   ],
   "source": [
    "def find_pattern_index(tensor, pattern, start_index=0):\n",
    "    pattern_length = pattern.size(0)\n",
    "    tensor_length = tensor.size(0)\n",
    "\n",
    "    for i in range(start_index, tensor_length - pattern_length + 1):\n",
    "        if torch.equal(tensor[i:i+pattern_length], pattern):\n",
    "            return i\n",
    "\n",
    "    return -1  # Return -1 if pattern is not found\n",
    "\n",
    "# Example tensor and pattern\n",
    "my_tensor = torch.tensor([123, 456, 331, 518, 25580, 29962, 518, 25580, 29962, 789, 518, 25580, 29962])\n",
    "my_pattern = torch.tensor([518, 25580, 29962])\n",
    "\n",
    "# Find the index of the first occurrence of the pattern starting from index 3\n",
    "start_index = 7\n",
    "index = find_pattern_index(my_tensor, my_pattern, start_index)\n",
    "\n",
    "if index != -1:\n",
    "    print(\"Pattern found at index:\", index)\n",
    "else:\n",
    "    print(\"Pattern not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "discount = 1.0\n",
    "gae_lambda = 0.95\n",
    "\n",
    "\n",
    "def compute_returns_and_advantages(v_t, r_t, v_tp1, done_tp1):\n",
    "    discount_tp1 = (~done_tp1).float() * discount\n",
    "\n",
    "    lambda_ = torch.ones_like(discount_tp1) * gae_lambda  # If scalar, make into vector.\n",
    "\n",
    "    delta_t = r_t + discount_tp1 * v_tp1 - v_t\n",
    "\n",
    "    advantage_t = torch.zeros_like(delta_t, dtype=torch.float32)\n",
    "\n",
    "    gae_t = 0\n",
    "    for i in reversed(range(len(delta_t))):\n",
    "        gae_t = delta_t[i] + discount_tp1[i] * lambda_[i] * gae_t\n",
    "        advantage_t[i] = gae_t\n",
    "\n",
    "    return_t = advantage_t + v_t\n",
    "\n",
    "    return return_t, advantage_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_returns_and_advantages(v_t, r_t, v_tp1, done_tp1):\n",
    "    num_rows, num_cols = v_t.shape  # Get the dimensions of the input data\n",
    "    discount_tp1 = (~done_tp1).float() * discount\n",
    "\n",
    "    lambda_ = torch.ones_like(discount_tp1) * gae_lambda  # If scalar, make into vector.\n",
    "\n",
    "    delta_t = r_t + discount_tp1 * v_tp1 - v_t\n",
    "\n",
    "    advantage_t = torch.zeros_like(delta_t, dtype=torch.float32)\n",
    "\n",
    "    return_t = torch.zeros_like(advantage_t, dtype=torch.float32)  # Initialize the return_t tensor\n",
    "\n",
    "    for row in range(num_rows):\n",
    "        gae_t = 0\n",
    "        for col in reversed(range(num_cols)):\n",
    "            gae_t = delta_t[row, col] + discount_tp1[row, col] * lambda_[row, col] * gae_t\n",
    "            advantage_t[row, col] = gae_t\n",
    "        return_t[row] = advantage_t[row] + v_t[row]\n",
    "\n",
    "    return return_t, advantage_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4929, 0.4977, 0.5029, 0.5083, 0.5140, 0.5200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200],\n",
      "        [0.4929, 0.4977, 0.5029, 0.5083, 0.5140, 0.5200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200],\n",
      "        [0.4929, 0.4977, 0.5029, 0.5083, 0.5140, 0.5200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200]])\n",
      "tensor([[0.4929, 0.4977, 0.5029, 0.5083, 0.5140, 0.5200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200],\n",
      "        [0.4929, 0.4977, 0.5029, 0.5083, 0.5140, 0.5200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200],\n",
      "        [0.4929, 0.4977, 0.5029, 0.5083, 0.5140, 0.5200, 0.0200, 0.0200, 0.0200,\n",
      "         0.0200]])\n"
     ]
    }
   ],
   "source": [
    "rewards = torch.ones((3, 10)) * 0.02\n",
    "rewards[:, 5] += 0.5\n",
    "values = torch.zeros((3, 10))\n",
    "values_tp1 = torch.zeros((3, 10))\n",
    "dones = torch.zeros((3, 10))\n",
    "dones[:, 5:] = 1\n",
    "\n",
    "dones = dones.to(dtype=torch.bool)\n",
    "\n",
    "returns, advantages = compute_returns_and_advantages(values, rewards, values_tp1, dones)\n",
    "\n",
    "print(returns)\n",
    "print(advantages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5474, 0.5552, 0.5633, 0.5719, 0.5810, 0.5905, 0.0742, 0.0570, 0.0390,\n",
      "         0.0200],\n",
      "        [0.5474, 0.5552, 0.5633, 0.5719, 0.5810, 0.5905, 0.0742, 0.0570, 0.0390,\n",
      "         0.0200],\n",
      "        [0.5474, 0.5552, 0.5633, 0.5719, 0.5810, 0.5905, 0.0742, 0.0570, 0.0390,\n",
      "         0.0200]])\n",
      "tensor([[0.5474, 0.5552, 0.5633, 0.5719, 0.5810, 0.5905, 0.0742, 0.0570, 0.0390,\n",
      "         0.0200],\n",
      "        [0.5474, 0.5552, 0.5633, 0.5719, 0.5810, 0.5905, 0.0742, 0.0570, 0.0390,\n",
      "         0.0200],\n",
      "        [0.5474, 0.5552, 0.5633, 0.5719, 0.5810, 0.5905, 0.0742, 0.0570, 0.0390,\n",
      "         0.0200]])\n"
     ]
    }
   ],
   "source": [
    "lastgaelam = 0\n",
    "advantages_reversed = []\n",
    "gen_length = 10\n",
    "for t in reversed(range(gen_length)):\n",
    "    nextvalues = values[:, t + 1] if t < gen_length - 1 else 0.0\n",
    "    delta = rewards[:, t] + discount * nextvalues - values[:, t]\n",
    "    lastgaelam = delta + discount * gae_lambda * lastgaelam\n",
    "    advantages_reversed.append(lastgaelam)\n",
    "advantages = torch.stack(advantages_reversed[::-1], dim=1)\n",
    "returns = advantages + values\n",
    "\n",
    "\n",
    "print(returns)\n",
    "print(advantages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "a  = [0, 1, 2, 3, 4, 5]\n",
    "\n",
    "len_a = len(a)\n",
    "\n",
    "print(a[2:len_a+1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
